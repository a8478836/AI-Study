{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLm05U8oM6f1lXhCY2IQBK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a8478836/AI-Study/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DybNNLlUmcBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "054042bc-8ce8-4d06-d90e-d95b8d88729b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset 111.45 MiB (download: 111.45 MiB, generated: Unknown size, total: 111.45 MiB) to ~/tensorflow_datasets/cycle_gan/horse2zebra/2.0.0...\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-23-3c26de3900b8>\", line 16, in <module>\n",
            "    dataset, _ = tfds.load(\"cycle_gan/horse2zebra\", with_info = True, as_supervised=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\", line 327, in load\n",
            "    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 460, in download_and_prepare\n",
            "    default_config_name=self.BUILDER_CONFIGS[0].name,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 1268, in _save_default_config_name\n",
            "    config_dir.mkdir(parents=True, exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/etils/epath/gpath.py\", line 168, in mkdir\n",
            "    self._backend.makedirs(self._path_str)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/etils/epath/backend.py\", line 114, in makedirs\n",
            "    os.makedirs(path, exist_ok=True)\n",
            "  File \"/usr/lib/python3.7/os.py\", line 213, in makedirs\n",
            "    makedirs(head, exist_ok=exist_ok)\n",
            "  File \"/usr/lib/python3.7/os.py\", line 213, in makedirs\n",
            "    makedirs(head, exist_ok=exist_ok)\n",
            "  File \"/usr/lib/python3.7/os.py\", line 213, in makedirs\n",
            "    makedirs(head, exist_ok=exist_ok)\n",
            "  File \"/usr/lib/python3.7/os.py\", line 223, in makedirs\n",
            "    mkdir(name, mode)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '~'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "#import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "autotune = tf.data.AUTOTUNE\n",
        "\n",
        "dataset, _ = tfds.load(\"cycle_gan/horse2zebra\", with_info = True, as_supervised=True)\n",
        "train_horses, train_zebras = dataset[\"trainA\"], dataset[\"trainB\"]\n",
        "test_hosrses, test_zebras = dataset[\"testA\"], dataset[\"testB\"]\n",
        "\n",
        "orig_img_size = (286, 286) # 평균 이미지 크기\n",
        "input_img_size = (256, 256, 3) # input image size, 만약 이미지 사이즈가 다 다르다면 맞춰줄 필요가 있음, 그리고 RGB이기 때문에 3임\n",
        "\n",
        "kernel_init = keras.initializers.RandomNormal(stddev=0.02) # 각 레이어별 layer의 weight 초기화 --> 1. 초기화 방법에 따른 결과를 비교해보자.\n",
        "\n",
        "!git push https://github.com/a8478836/AI-Study.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "As13Mhe9nVXQ"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}